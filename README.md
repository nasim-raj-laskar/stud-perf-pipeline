# Student Performance Prediction - Production-Grade MLOps Pipeline

Enterprise-level machine learning system implementing comprehensive MLOps practices with automated CI/CD pipelines, containerized microservices architecture, and cloud-native deployment strategies. Features production-ready model serving, automated model retraining, and infrastructure-as-code deployment patterns.

## ğŸ›ï¸ System Architecture

![Architecture Diagram](static/img/flow.png)

## ğŸ¯ Project Overview

This project predicts student math performance using features like:
- Gender
- Race/Ethnicity 
- Parental level of education
- Lunch type (standard/free or reduced)
- Test preparation course completion
- Reading and writing scores

## ğŸ—ï¸ Project Architecture

```
ETE-project-3/
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ components/                 # ML pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py       # Data loading and splitting
â”‚   â”‚   â”œâ”€â”€ data_transformation.py  # Feature engineering
â”‚   â”‚   â””â”€â”€ model_trainer.py        # Model training and evaluation
â”‚   â”œâ”€â”€ pipeline/                   # Prediction pipelines
â”‚   â”‚   â”œâ”€â”€ predict_pipeline.py     # Inference pipeline
â”‚   â”‚   â””â”€â”€ train_pipeline.py       # Training pipeline
â”‚   â”œâ”€â”€ exception.py                # Custom exception handling
â”‚   â”œâ”€â”€ logger.py                   # Logging configuration
â”‚   â””â”€â”€ utils.py                    # Utility functions
â”œâ”€â”€ notebook/                       # Jupyter notebooks
â”‚   â”œâ”€â”€ EDA.ipynb                   # Exploratory Data Analysis
â”‚   â”œâ”€â”€ Model.ipynb                 # Model experimentation
â”‚   â”œâ”€â”€ data/stud.csv               # Dataset
â”‚   â”œâ”€â”€ plots/                      # Visualization outputs
â”‚   â””â”€â”€ savedmodel/                 # Trained models
â”œâ”€â”€ artifacts/                      # Generated artifacts
â”‚   â”œâ”€â”€ model.pkl                   # Final trained model
â”‚   â”œâ”€â”€ preprocessor.pkl            # Data preprocessor
â”‚   â””â”€â”€ *.csv                       # Processed datasets
â”œâ”€â”€ templates/                      # HTML templates
â”œâ”€â”€ static/                         # CSS/JS files
â”œâ”€â”€ logs/                           # Application logs
â”œâ”€â”€ app.py                          # Flask web application
â”œâ”€â”€ Dockerfile                      # Container configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ setup.py                        # Package setup
```

## ğŸš€ Technical Architecture

- **Production ML Pipeline**: Automated ETL, feature engineering, model training with hyperparameter optimization
- **Microservices Architecture**: Flask-based REST API with containerized deployment
- **Multi-Model Evaluation**: Ensemble methods with cross-validation and automated model selection
- **Observability Stack**: Structured logging, metrics collection, and distributed tracing
- **Container Orchestration**: Docker containerization with multi-stage builds
- **GitOps Workflow**: Infrastructure-as-code with automated CI/CD pipelines
- **Cloud-Native Design**: Scalable, stateless services with horizontal scaling capabilities

## ğŸ“Š Models Evaluated

- Linear Regression
- Ridge Regression
- Lasso Regression
- Decision Tree Regressor
- Random Forest Regressor
- AdaBoost Regressor
- XGBoost Regressor
- CatBoost Regressor
- K-Neighbors Regressor

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.12+
- pip
- Docker 

### Local Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ETE-project-3
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install package in development mode**
   ```bash
   pip install -e .
   ```

### Docker Setup

1. **Build Docker image**
   ```bash
   docker build -t student-performance-app .
   ```

2. **Run container**
   ```bash
   docker run -p 8080:8080 student-performance-app
   ```

## ğŸ® Usage

### Training the Model

```bash
python src/components/data_ingestion.py
```

### Running the Web Application

```bash
python app.py
```

Access the application at `http://localhost:8080`

### Making Predictions

The web interface allows you to:
1. Select student demographics
2. Enter reading and writing scores
3. Get predicted math score

## ğŸ“ˆ Model Performance

The final model selection is based on:
- RÂ² Score
- Mean Absolute Error (MAE)
- Root Mean Square Error (RMSE)

Detailed performance metrics are available in the training logs.

## âš™ï¸ Infrastructure Configuration

### Environment Variables
```bash
# AWS Infrastructure
AWS_ACCESS_KEY_ID=<access_key>
AWS_SECRET_ACCESS_KEY=<secret_key>
AWS_REGION=us-east-1
ECR_REPOSITORY_NAME=student-performance
AWS_ECR_LOGIN_URI=<account_id>.dkr.ecr.us-east-1.amazonaws.com


### Directory Structure
```
artifacts/          # Model artifacts and preprocessors
logs/              # Application and system logs
notebook/data/     # Training datasets
static/           # Frontend assets
templates/        # Jinja2 templates
```

## ğŸš€ CI/CD Pipeline & Deployment Architecture

### GitHub Actions Workflow

```yaml
# .github/workflows/main.yml
name: MLOps Production Pipeline

on:
  push:
    branches: [main]
    paths-ignore: ['README.md']

jobs:
  continuous-integration:
    runs-on: ubuntu-latest
    steps:
      - name: Code Quality Gates
        run: |
          echo "Static code analysis"
          echo "Security vulnerability scanning"
          echo "Unit test execution"
          echo "Integration test suite"
```

### Container Orchestration

**Multi-stage Dockerfile:**
```dockerfile
FROM python:3.12.5-slim-bookworm
WORKDIR /app
COPY . /app

# System dependencies
RUN apt update -y && apt install awscli -y

# Python dependencies
RUN pip install -r requirements.txt
CMD ["python3", "app.py"]
```

### Production Deployment Strategies

#### 1. AWS ECS + ECR (Recommended)
```bash
# Build and push to ECR
docker build -t student-performance .
docker tag student-performance:latest $ECR_URI:latest
docker push $ECR_URI:latest

# Deploy to ECS
aws ecs update-service --cluster production --service student-performance-service
```

#### 2. AWS EC2 Auto Scaling
```bash
# Pull latest image
docker pull $ECR_URI:latest

# Zero-downtime deployment
docker run -d -p 8080:8080 \
  --name student-performance \
  --restart unless-stopped \
  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
  $ECR_URI:latest
```

## ğŸ“¡ REST API Specification

### Core Endpoints

```http
GET /health
Content-Type: application/json
Response: {"status": "healthy", "timestamp": "2024-01-01T00:00:00Z"}

GET /metrics
Content-Type: text/plain
Response: Prometheus metrics format

GET /
Content-Type: text/html
Response: Application landing page

GET /predictdata
Content-Type: text/html
Response: Prediction form interface

POST /predictdata
Content-Type: application/x-www-form-urlencoded
Payload: {
  "gender": "male|female",
  "ethnicity": "group A|B|C|D|E",
  "parental_level_of_education": "string",
  "lunch": "standard|free/reduced",
  "test_preparation_course": "none|completed",
  "reading_score": "float[0-100]",
  "writing_score": "float[0-100]"
}
Response: {"prediction": float, "confidence": float}
```



## ğŸ“Š Data Schema

| Feature | Type | Description |
|---------|------|-------------|
| gender | categorical | Student gender (male/female) |
| race_ethnicity | categorical | Race/ethnicity group (A-E) |
| parental_level_of_education | categorical | Parent education level |
| lunch | categorical | Lunch type (standard/free or reduced) |
| test_preparation_course | categorical | Test prep completion (none/completed) |
| reading_score | numerical | Reading test score (0-100) |
| writing_score | numerical | Writing test score (0-100) |
| math_score | numerical | **Target**: Math test score (0-100) |





